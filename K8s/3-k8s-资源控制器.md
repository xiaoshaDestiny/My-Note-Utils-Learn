# Kubernetes资源控制器
Pod的简单分类    
1、自主式Pod：死亡之后不会被拉起。  
2、控制器管理的Pod：会有控制器去管理Pod的生命周期，始终要维持Pod的副本数目。  

**K8s的控制器相当于一个状态机，用来控制这些Pod的具体状态和行为**

## 控制器类型
1. ReplicationController (RC) 和 ReplicaSet (RS)  
2. Deployment  
3. DaemonSet  
4. StateFulSet  
5. Job/CornJob  
6. Horizontal Pod Autoscaling  

### ReplicationController (RC) 和 ReplicaSet (RS)
RC 用来确保容器应用的副本数目始终保持在用户定义的副本数目，如果有容器异常退出，会自动创建新的Pod来代替，而如果异常多出来的容器也会自动回收。  
在新版本的kubernetes中，建议使用RS来取代RC，没有本质的不同，并且RS支持集合式的selector。  

### Deployment
Deployment为Pod和RS提供了一个 **声明式定义** 的办法，用来代替RC来管理应用，典型的场景是：  
- 定义Deployment来创建Pod和RS。Deployment去创建RS，RS再去创建Pod
- 滚动升级和回滚应用
- 扩容和缩容
- 暂停和继续Deployment

### DaemonSet
DaemonSet确保全部或者一些Node上运行一个Pod的副本。当有Node加入集群的时候，也会为他们新增一个Pod.
当有Node从集群中移除的时候，这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod。  
DaemonSet的一些典型用法：  
- 运行集群存储daemon,例如在每一个Node上运行glusterd、ceph
- 在每一个Node上运行日志收集daemon，例如fluentd、logstash
- 在每一个Node上运行监控daemon，例如Promentheus Node Exporter、collected、Datadog代理、NewRelic代理或者Ganglia gmond

### Job
如果只是写一个定时任务的脚本放在Linux的Corn table里面去执行的话，如果没有对应的纠错功能的话，就会不好处理报错。
- 负责批处理任务，即仅执行一次任务，它保证批处理任务的一个或者多个Pod成功结束。

### CornJob
Cron Job管理基于时间的Job，在给定的时间点只运行一次，周期性的在给定的时间点运行  
在特定的时间循环创建job  
分 时 日 月 周  
在给定的时间点调度Job运行，创建周期性的job，数据库备份，发送邮件等

### StatefulSet
为了解决有状态服务问题，k8s提供了StatefulSet  
StatefulSet作为Controller为Pod提供唯一的标识，它可以保证部署和scale的顺序。应用场景主要有：
- 稳定的持久化存储，Pod重新调度之后还是能够访问到相同的持久化数据，基于PVC来实现。
- 稳定的网络标志，Pod重新调度后其PodName和HostName不变，基于Headless Service（没有Cluster Ip的Service）来实现。
- 有序部署，有序扩展。Pod是有序的，在部署或者扩展的时候要根据定义的顺序依次进行。
 （从0 到 n-1，在下一个Pod运行之前所有的Pod必须是Running和Ready状态），基于init containers来实现。
- 有序收缩，有序删除

### Horizontal Pod Autoscaling (HPA)
应用的资源使用率通常都有高峰和低谷的时候，如何削峰填谷，提供集群的整体资源利用率，需要依赖于Horizontal Pod Autoscaling让service中的Pod个数自动调整，水平自动缩放。


## RS RC 和 Deployment

### RS
```
查看RS相关的命令： kubectl explain rs

vim rs.yaml

apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: frontend
spec:
  replicas: 3              #三个副本数目
  selector:                #选择标签
    matchLabels:           #匹配
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: myapp
        image: hub.xiaosha.com/library/myapp:v1
        env:
        - name: GET_HOSTS_FROM
          value: dns
        ports:
        - containerPort: 80
       


kubectl create -f rs.yaml 
replicaset.extensions/frontend created

[root@k8s-master01 ~]# kubectl get pod
NAME             READY   STATUS    RESTARTS   AGE
frontend-l5gdz   1/1     Running   0          9s
frontend-n2gsx   1/1     Running   0          9s
frontend-zv2nw   1/1     Running   0          9s

#删除Pod之后，资源控制器定义的Pod还会根据期望着存在。

#查看RS资源控制器

[root@k8s-master01 ~]# kubectl get rs
NAME       DESIRED   CURRENT   READY   AGE
frontend   3         3         3       2m14s

#查看Pod的标签                
kubectl get pod --show-labels

[root@k8s-master01 ~]# kubectl get pod --show-labels
NAME             READY   STATUS    RESTARTS   AGE     LABELS
frontend-l5gdz   1/1     Running   0          5m58s   tier=frontend
frontend-n2gsx   1/1     Running   0          5m58s   tier=frontend
frontend-zv2nw   1/1     Running   0          5m58s   tier=frontend
[root@k8s-master01 ~]# kubectl label pod frontend-l5gdz tier=frontend001
error: 'tier' already has a value (frontend), and --overwrite is false
[root@k8s-master01 ~]# kubectl label pod frontend-l5gdz tier=frontend001 --overwrite=true
pod/frontend-l5gdz labeled
[root@k8s-master01 ~]# kubectl get pod --show-labels
NAME             READY   STATUS    RESTARTS   AGE    LABELS
frontend-l5gdz   1/1     Running   0          7m4s   tier=frontend001
frontend-lj8vh   1/1     Running   0          4s     tier=frontend
frontend-n2gsx   1/1     Running   0          7m4s   tier=frontend
frontend-zv2nw   1/1     Running   0          7m4s   tier=frontend

修改标签之后，Pod的数目变成了四个，因为标签选择名字不一样，还是去维持副本数目
所以kubernetes在监控副本数目的时候是以标签选择为基础的
这样在删除这个RS的时候，其实对应的也是删除这个标签下的pod

[root@k8s-master01 ~]# kubectl get rs
NAME       DESIRED   CURRENT   READY   AGE
frontend   3         3         3       10m
[root@k8s-master01 ~]# kubectl delete rs --all
replicaset.extensions "frontend" deleted
[root@k8s-master01 ~]# kubectl get pod --show-labels
NAME             READY   STATUS    RESTARTS   AGE   LABELS
frontend-l5gdz   1/1     Running   0          11m   tier=frontend001
删除之后也只有这个修改过标签的pod依旧存在

```

### Deployment
```
vim deployment.yml

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3              #三个副本数目
  template:
    metadata:
      labels:
        tier: nginx
    spec:
      containers:
      - name: nginx
        image: hub.xiaosha.com/library/myapp:v1
        ports:
        - containerPort: 80


kubectl create -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record
## --record参数可以记录命令，我们可以很方便的查看每次 revision 的变化

[root@k8s-master01 ~]# kubectl apply -f deployment.yml --record
deployment.extensions/nginx-deployment created
[root@k8s-master01 ~]# kubectl get deployment
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           9s
[root@k8s-master01 ~]# 

```
### 扩容
kubectl scale deployment nginx-deployment --replicas=10
### 更新
kubectl set images deployment/nginx-deployment nginx=wangyanglinux/myapp:v2






























