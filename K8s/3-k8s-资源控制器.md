# Kubernetes资源控制器
Pod的简单分类    
1、自主式Pod：死亡之后不会被拉起。  
2、控制器管理的Pod：会有控制器去管理Pod的生命周期，始终要维持Pod的副本数目。  

**K8s的控制器相当于一个状态机，用来控制这些Pod的具体状态和行为**

## 控制器类型
1. ReplicationController (RC) 和 ReplicaSet (RS)  
2. Deployment  
3. DaemonSet  
4. StateFulSet  
5. Job/CornJob  
6. Horizontal Pod Autoscaling  

### ReplicationController (RC) 和 ReplicaSet (RS)
RC 用来确保容器应用的副本数目始终保持在用户定义的副本数目，如果有容器异常退出，会自动创建新的Pod来代替，而如果异常多出来的容器也会自动回收。  
在新版本的kubernetes中，建议使用RS来取代RC，没有本质的不同，并且RS支持集合式的selector。  

### Deployment
Deployment为Pod和RS提供了一个 **声明式定义** 的办法，用来代替RC来管理应用，典型的场景是：  
- 定义Deployment来创建Pod和RS。Deployment去创建RS，RS再去创建Pod
- 滚动升级和回滚应用
- 扩容和缩容
- 暂停和继续Deployment

### DaemonSet
DaemonSet确保全部或者一些Node上运行一个Pod的副本。当有Node加入集群的时候，也会为他们新增一个Pod.
当有Node从集群中移除的时候，这些Pod也会被回收。删除DaemonSet将会删除它创建的所有Pod。  
DaemonSet的一些典型用法：  
- 运行集群存储daemon,例如在每一个Node上运行glusterd、ceph
- 在每一个Node上运行日志收集daemon，例如fluentd、logstash
- 在每一个Node上运行监控daemon，例如Promentheus Node Exporter、collected、Datadog代理、NewRelic代理或者Ganglia gmond

### Job
如果只是写一个定时任务的脚本放在Linux的Corn table里面去执行的话，如果没有对应的纠错功能的话，就会不好处理报错。
- 负责批处理任务，即仅执行一次任务，它保证批处理任务的一个或者多个Pod成功结束。

### CornJob
Cron Job管理基于时间的Job，在给定的时间点只运行一次，周期性的在给定的时间点运行  
在特定的时间循环创建job  
分 时 日 月 周  
在给定的时间点调度Job运行，创建周期性的job，数据库备份，发送邮件等

### StatefulSet
为了解决有状态服务问题，k8s提供了StatefulSet  
StatefulSet作为Controller为Pod提供唯一的标识，它可以保证部署和scale的顺序。应用场景主要有：
- 稳定的持久化存储，Pod重新调度之后还是能够访问到相同的持久化数据，基于PVC来实现。
- 稳定的网络标志，Pod重新调度后其PodName和HostName不变，基于Headless Service（没有Cluster Ip的Service）来实现。
- 有序部署，有序扩展。Pod是有序的，在部署或者扩展的时候要根据定义的顺序依次进行。
 （从0 到 n-1，在下一个Pod运行之前所有的Pod必须是Running和Ready状态），基于init containers来实现。
- 有序收缩，有序删除

### Horizontal Pod Autoscaling (HPA)
应用的资源使用率通常都有高峰和低谷的时候，如何削峰填谷，提供集群的整体资源利用率，需要依赖于Horizontal Pod Autoscaling让service中的Pod个数自动调整，水平自动缩放。


## RS RC 和 Deployment

### RS
```
查看RS相关的命令： kubectl explain rs

vim rs.yaml

apiVersion: extensions/v1beta1
kind: ReplicaSet
metadata:
  name: frontend
spec:
  replicas: 3              #三个副本数目
  selector:                #选择标签
    matchLabels:           #匹配
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: myapp
        image: hub.xiaosha.com/library/myapp:v1
        env:
        - name: GET_HOSTS_FROM
          value: dns
        ports:
        - containerPort: 80
       


kubectl create -f rs.yaml 
replicaset.extensions/frontend created

[root@k8s-master01 ~]# kubectl get pod
NAME             READY   STATUS    RESTARTS   AGE
frontend-l5gdz   1/1     Running   0          9s
frontend-n2gsx   1/1     Running   0          9s
frontend-zv2nw   1/1     Running   0          9s

#删除Pod之后，资源控制器定义的Pod还会根据期望着存在。

#查看RS资源控制器

[root@k8s-master01 ~]# kubectl get rs
NAME       DESIRED   CURRENT   READY   AGE
frontend   3         3         3       2m14s

#查看Pod的标签                
kubectl get pod --show-labels

[root@k8s-master01 ~]# kubectl get pod --show-labels
NAME             READY   STATUS    RESTARTS   AGE     LABELS
frontend-l5gdz   1/1     Running   0          5m58s   tier=frontend
frontend-n2gsx   1/1     Running   0          5m58s   tier=frontend
frontend-zv2nw   1/1     Running   0          5m58s   tier=frontend
[root@k8s-master01 ~]# kubectl label pod frontend-l5gdz tier=frontend001
error: 'tier' already has a value (frontend), and --overwrite is false
[root@k8s-master01 ~]# kubectl label pod frontend-l5gdz tier=frontend001 --overwrite=true
pod/frontend-l5gdz labeled
[root@k8s-master01 ~]# kubectl get pod --show-labels
NAME             READY   STATUS    RESTARTS   AGE    LABELS
frontend-l5gdz   1/1     Running   0          7m4s   tier=frontend001
frontend-lj8vh   1/1     Running   0          4s     tier=frontend
frontend-n2gsx   1/1     Running   0          7m4s   tier=frontend
frontend-zv2nw   1/1     Running   0          7m4s   tier=frontend

修改标签之后，Pod的数目变成了四个，因为标签选择名字不一样，还是去维持副本数目
所以kubernetes在监控副本数目的时候是以标签选择为基础的
这样在删除这个RS的时候，其实对应的也是删除这个标签下的pod

[root@k8s-master01 ~]# kubectl get rs
NAME       DESIRED   CURRENT   READY   AGE
frontend   3         3         3       10m
[root@k8s-master01 ~]# kubectl delete rs --all
replicaset.extensions "frontend" deleted
[root@k8s-master01 ~]# kubectl get pod --show-labels
NAME             READY   STATUS    RESTARTS   AGE   LABELS
frontend-l5gdz   1/1     Running   0          11m   tier=frontend001
删除之后也只有这个修改过标签的pod依旧存在

```

### Deployment
```
vim deployment.yml

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3              #三个副本数目
  template:
    metadata:
      labels:
        tier: nginx
    spec:
      containers:
      - name: nginx
        image: hub.xiaosha.com/library/myapp:v1
        ports:
        - containerPort: 80


kubectl create -f https://kubernetes.io/docs/user-guide/nginx-deployment.yaml --record
## --record参数可以记录命令，我们可以很方便的查看每次 revision 的变化

[root@k8s-master01 ~]# kubectl apply -f deployment.yml --record
deployment.extensions/nginx-deployment created
[root@k8s-master01 ~]# kubectl get deployment
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           9s
[root@k8s-master01 ~]# 

```
### 扩容
kubectl scale deployment nginx-deployment --replicas=6


### 更新
kubectl set images deployment/nginx-deployment nginx=hub.xiaosha.com/library/myapp:v2

在k8s中，更新的策略可以是先生成25%的新Pod，然后删除老旧版本25%的旧Pod。这个数值是可以调整的。

``` 
[root@k8s-master01 ~]# kubectl set image deployment/nginx-deployment nginx=hub.xiaosha.com/library/myapp:v2
deployment.extensions/nginx-deployment image updated

[root@k8s-master01 ~]# kubectl get pod -o wide
NAME                                READY   STATUS              RESTARTS   AGE   IP            NODE         NOMINATED NODE   READINESS GATES
nginx-deployment-5f4654b79b-45rpx   1/1     Running             0          4s    10.244.2.26   k8s-node02   <none>           <none>
nginx-deployment-5f4654b79b-8cvvj   1/1     Running             0          4s    10.244.1.18   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-bxqzz   0/1     ContainerCreating   0          0s    <none>        k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-mxx8l   0/1     ContainerCreating   0          1s    <none>        k8s-node02   <none>           <none>
nginx-deployment-84886c488f-27pdk   1/1     Running             1          20h   10.244.1.17   k8s-node01   <none>           <none>
nginx-deployment-84886c488f-4rmzl   1/1     Terminating         1          20h   10.244.2.25   k8s-node02   <none>           <none>
nginx-deployment-84886c488f-dzlsb   0/1     Terminating         1          20h   10.244.2.23   k8s-node02   <none>           <none>
nginx-deployment-84886c488f-l28zk   1/1     Running             1          20h   10.244.1.15   k8s-node01   <none>           <none>
nginx-deployment-84886c488f-nnf2q   1/1     Running             1          20h   10.244.1.16   k8s-node01   <none>           <none>

[root@k8s-master01 ~]# kubectl get pod -o wide
NAME                                READY   STATUS        RESTARTS   AGE   IP            NODE         NOMINATED NODE   READINESS GATES
nginx-deployment-5f4654b79b-45rpx   1/1     Running       0          12s   10.244.2.26   k8s-node02   <none>           <none>
nginx-deployment-5f4654b79b-8cvvj   1/1     Running       0          12s   10.244.1.18   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-bxqzz   1/1     Running       0          8s    10.244.1.19   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-g4jh6   1/1     Running       0          7s    10.244.2.28   k8s-node02   <none>           <none>
nginx-deployment-5f4654b79b-k6dz6   1/1     Running       0          5s    10.244.1.20   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-mxx8l   1/1     Running       0          9s    10.244.2.27   k8s-node02   <none>           <none>
nginx-deployment-84886c488f-27pdk   0/1     Terminating   1          20h   10.244.1.17   k8s-node01   <none>           <none>
nginx-deployment-84886c488f-l28zk   0/1     Terminating   1          20h   10.244.1.15   k8s-node01   <none>           <none>
nginx-deployment-84886c488f-nnf2q   0/1     Terminating   1          20h   10.244.1.16   k8s-node01   <none>           <none>

[root@k8s-master01 ~]# kubectl get pod -o wide
NAME                                READY   STATUS    RESTARTS   AGE   IP            NODE         NOMINATED NODE   READINESS GATES
nginx-deployment-5f4654b79b-45rpx   1/1     Running   0          25s   10.244.2.26   k8s-node02   <none>           <none>
nginx-deployment-5f4654b79b-8cvvj   1/1     Running   0          25s   10.244.1.18   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-bxqzz   1/1     Running   0          21s   10.244.1.19   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-g4jh6   1/1     Running   0          20s   10.244.2.28   k8s-node02   <none>           <none>
nginx-deployment-5f4654b79b-k6dz6   1/1     Running   0          18s   10.244.1.20   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-mxx8l   1/1     Running   0          22s   10.244.2.27   k8s-node02   <none>           <none>


镜像的修改触发了RS的创建
[root@k8s-master01 ~]# kubectl get deployment
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   6/6     6            6           20h

[root@k8s-master01 ~]# kubectl get rs
NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-5f4654b79b   6         6         6       2m56s
nginx-deployment-84886c488f   0         0         0       20h
```

### 回滚
kubectl rollout undo deployment/nginx-deployment

```
[root@k8s-master01 ~]# kubectl rollout undo deployment/nginx-deployment
deployment.extensions/nginx-deployment rolled back
[root@k8s-master01 ~]# kubectl get pod -o wide
NAME                                READY   STATUS              RESTARTS   AGE    IP            NODE         NOMINATED NODE   READINESS GATES
nginx-deployment-5f4654b79b-45rpx   1/1     Running             0          172m   10.244.2.26   k8s-node02   <none>           <none>
nginx-deployment-5f4654b79b-8cvvj   1/1     Running             0          172m   10.244.1.18   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-bxqzz   0/1     Terminating         0          172m   10.244.1.19   k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-g4jh6   1/1     Running             0          172m   10.244.2.28   k8s-node02   <none>           <none>
nginx-deployment-5f4654b79b-k6dz6   0/1     Terminating         0          172m   <none>        k8s-node01   <none>           <none>
nginx-deployment-5f4654b79b-mxx8l   1/1     Running             0          172m   10.244.2.27   k8s-node02   <none>           <none>
nginx-deployment-84886c488f-dsrz7   1/1     Running             0          5s     10.244.1.21   k8s-node01   <none>           <none>
nginx-deployment-84886c488f-h959d   0/1     ContainerCreating   0          5s     <none>        k8s-node02   <none>           <none>
nginx-deployment-84886c488f-ttf82   0/1     ContainerCreating   0          3s     <none>        k8s-node02   <none>           <none>

[root@k8s-master01 ~]# kubectl get pod -o wide
NAME                                READY   STATUS    RESTARTS   AGE   IP            NODE         NOMINATED NODE   READINESS GATES
nginx-deployment-84886c488f-dsrz7   1/1     Running   0          26s   10.244.1.21   k8s-node01   <none>           <none>
nginx-deployment-84886c488f-h959d   1/1     Running   0          26s   10.244.2.29   k8s-node02   <none>           <none>
nginx-deployment-84886c488f-pzfzq   1/1     Running   0          20s   10.244.2.31   k8s-node02   <none>           <none>
nginx-deployment-84886c488f-rfwlw   1/1     Running   0          18s   10.244.1.23   k8s-node01   <none>           <none>
nginx-deployment-84886c488f-ttf82   1/1     Running   0          24s   10.244.2.30   k8s-node02   <none>           <none>
nginx-deployment-84886c488f-vl792   1/1     Running   0          20s   10.244.1.22   k8s-node01   <none>           <none>

[root@k8s-master01 ~]# kubectl get rs
NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-5f4654b79b   0         0         0       173m
nginx-deployment-84886c488f   6         6         6       23h


[root@k8s-master01 ~]# kubectl get deployment
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   6/6     6            6           23h


#查看更新状态
[root@k8s-master01 ~]# kubectl rollout status deployments  nginx-deployment
deployment "nginx-deployment" successfully rolled out

#查看历史版本
[root@k8s-master01 ~]# kubectl rollout history deployment/nginx-deployment
deployment.extensions/nginx-deployment 
REVISION  CHANGE-CAUSE
2         kubectl apply --filename=deployment.yml --record=true
3         kubectl apply --filename=deployment.yml --record=true

#回退到指定的版本
kubectl rollout undo deployment/nginx-deployment --to-revision-2

#暂停deployment的更新
kubectl rollout pause deployment/nginx-deployment

```

## Daemonset Job CornJob

### Daemonset 每个节点只有一份
```
vim daemonset.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: deamonset-example
  labels:
    app: daemonset
spec:
  selector:
    matchLabels:
      name: deamonset-example
  template:
    metadata:
      labels:
        name: deamonset-example
    spec:
      containers:
      - name: daemonset-example
        image: hub.xiaosha.com/library/myapp:v1
        
kubectl apply -f daemonset.yaml  


[root@k8s-master01 ~]# kubectl apply -f daemonset.yaml
daemonset.apps/deamonset-example created

[root@k8s-master01 ~]# kubectl get pod
NAME                                READY   STATUS    RESTARTS   AGE
deamonset-example-h2jng             1/1     Running   0          3m3s
deamonset-example-z7774             1/1     Running   0          3m3s

[root@k8s-master01 ~]# kubectl delete pod deamonset-example-h2jng
pod "deamonset-example-h2jng" deleted

[root@k8s-master01 ~]# kubectl get pod -o wide
NAME                                READY   STATUS    RESTARTS   AGE     IP            NODE         NOMINATED NODE   READINESS GATES
deamonset-example-dh2hk             1/1     Running   0          8s      10.244.2.33   k8s-node02   <none>           <none>
deamonset-example-z7774             1/1     Running   0          5m18s   10.244.1.24   k8s-node01   <none>           <none>
   
```

### Job 仅仅执行一次

```
vim job.yaml

apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    metadata:
      name: pi
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never



docker load -i perl.tar
scp perl.tar root@k8s-node01:/root/


 
[root@k8s-master01 ~]# kubectl get job
NAME   COMPLETIONS   DURATION   AGE
pi     1/1           46s        10m

[root@k8s-master01 ~]# kubectl get pod
NAME                                READY   STATUS      RESTARTS   AGE
pi-xzv9p                            0/1     Completed   0          10m
       
[root@k8s-master01 ~]# kubectl log pi-xzv9p
log is DEPRECATED and will be removed in a future version. Use logs instead.

3.
1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679 
8214808651328230664709384460955058223172535940812848111745028410270193852110555964462294895493038196
4428810975665933446128475648233786783165271201909145648566923460348610454326648213393607260249141273
7245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094
3305727036575959195309218611738193261179310511854807446237996274956735188575272489122793818301194912
9833673362440656643086021394946395224737190702179860943702770539217176293176752384674818467669405132
0005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235
4201995611212902196086403441815981362977477130996051870721134999999837297804995105973173281609631859
5024459455346908302642522308253344685035261931188171010003137838752886587533208381420617177669147303
5982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989
3809525720106548586327886593615338182796823030195203530185296899577362259941389124972177528347913151
5574857242454150695950829533116861727855889075098381754637464939319255060400927701671139009848824012
8583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912
9331367702898915210475216205696602405803815019351125338243003558764024749647326391419927260426992279
6782354781636009341721641219924586315030286182974555706749838505494588586926995690927210797509302955
3211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000
8164706001614524919217321721477235014144197356854816136115735255213347574184946843852332390739414333
4547762416862518983569485562099219222184272550254256887671790494601653466804988627232791786085784383
8279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863
067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901

```



### CornJob 定时执行


spec.schedule ：调度，必需字段，指定任务运行周期，格式同 Cron  
spec.jobTemplate ：Job 模板，必需字段，指定需要运行的任务，格式同 Job  
spec.startingDeadlineSeconds ：启动 Job 的期限（秒级别），该字段是可选的。如果因为任何原因而错过了被调度的时间，那么错过执行时间的 Job 将被认为是失败的。
如果没有指定，则没有期限  
spec.concurrencyPolicy ：并发策略，该字段也是可选的。它指定了如何处理被 Cron Job 创建的 Job 的并发执行。只允许指定下面策略中的一种：  
Allow （默认）：允许并发运行 Job
Forbid ：禁止并发运行，如果前一个还没有完成，则直接跳过下一个
Replace ：取消当前正在运行的 Job，用一个新的来替换

注意，当前策略只能应用于同一个 Cron Job 创建的 Job。如果存在多个 Cron Job，它们创建的 Job 之间总是允许并发运行。
spec.suspend ：挂起，该字段也是可选的。如果设置为  true ，后续所有执行都会被挂起。它对已经开始执行的 Job 不起作用。默认值为  false 。
spec.successfulJobsHistoryLimit 和  .spec.failedJobsHistoryLimit ：历史限制，是可选的字段。它们指定了可以保留多少完成和失败的 Job。默认情况下，它们分别设置为  3 和  1 。设置限制的值为  0 ，相关类型的 Job 完成后将不会被保留。


```

apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailur
                

[root@k8s-master01 ~]# kubectl apply -f cornjob.yaml 
cronjob.batch/hello created


[root@k8s-master01 ~]# kubectl get cronjob
NAME    SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
hello   */1 * * * *   False     0        <none>          26s


[root@k8s-master01 ~]# kubectl get job
NAME               COMPLETIONS   DURATION   AGE
hello-1592638800   1/1           37s        41s
pi                 1/1           46s        20m


[root@k8s-master01 ~]# kubectl get pod
NAME                     READY   STATUS              RESTARTS   AGE
hello-1592638860-kvgvw   0/1     Completed           0          3m8s
hello-1592638920-zj2rw   0/1     Completed           0          2m8s
hello-1592638980-9hksj   0/1     Completed           0          68s
hello-1592639040-gzqdz   0/1     ContainerCreating   0          7s

[root@k8s-master01 ~]# kubectl log hello-1592639040-gzqdz
log is DEPRECATED and will be removed in a future version. Use logs instead.
Sat Jun 20 07:44:25 UTC 2020
Hello from the Kubernetes cluster --xiaosha

```


























