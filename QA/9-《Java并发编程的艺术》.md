《Java并发编程的艺术》
# 第一章 并发编程的挑战
## 上下文切换
CPU给每个任务分配时间片，CPU不停的切换线程执行。任务从保存到加载就是一次上下文的切换。   
创建多的线程不一定会使得执行效果高于单线程处理，因为CPU上下文的切换也会带来恨大的性能开销。   
### 如何减少上下文的切换
(1)无锁并发编程，将数据按照ID进行Hash运算取模分段，不同的线程处理不同段的数据。   
(2)CAS 自旋操作，Atomic包下的包装数据类型使用了CAS算法来进行数据更新，不需要加锁。   
(3)使用协程，使用最少线程，避免创建不需要的线程，在单线程里面实现多任务调度，并在单线程里维持多个任务之间的切换。 
### 避免死锁
(1)避免一个线程同时获取多个锁。  
(2)避免一个线程在锁内部同时占用说个资源，尽量保证一个锁占用一个资源。
(3)尝试使用定时锁，使用try-lock来替代使用内部锁机制。  
(4)对于数据库锁，加锁和解锁必须是在一个数据库连接里面，否则会出现解锁失败的情况。  
### 资源限制带来的挑战
程序执行的速度受到软硬件资源的限制。并发编程的原则是将串行代码执行的部分变成并发执行，但是因为资源的限制，程序可能不仅不会加快，反而因为CPU上下文的切换导致资源调度的时间更长。  
2Mb/s的带宽，下载速度是1Mb/s，启动多个线程之后不会变成10Mb/s  
如果是硬件资源带来的限制，可以考虑集群方案。不同的数据交给不同的机器去处理。数据ID%机器数量取模，得到的就是处理这个数据的机器编号。  
对于软件资源来限制，可以采用资源的复用策略，使用连接池将数据库连接和Socket连接复用，或者在调用服务获取接口的时候，只建立一个连接。  

# 第二章 Java并发机制的底层实现原理
## volatile的应用

如果一个变量被声明为 volatile ,Java的线程内存模型能够确保所有线程看到这个变量的值是一致的。

### CPU术语
内存屏障：一组处理器指令，用来实现对内存操作的顺序限制  
缓冲行：缓存中可以分配的最小存储单位。处理器填写缓存线的时候会加载整个缓存线需要使用多个主内存读周期  
原子操作：不可中断的一个或者一系列操作  
缓存行填充：当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存(L1,L2,L3)  
缓存命中：如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存中读取  
写命中：当处理器将操作数写回到一个内存缓存的区域时，它会首先检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中    
写缺失：一个有效的缓存行被写入到不同的内存区域  

### 如何保证可见性？
在堆volatile变量进行写操作的时候，会编译生成一个Lock前缀的CPU指令，在多核的CPU处理器下回引发两件事情：  
1、将当前处理器缓存行的数据写回到系统内存中。  
2、这个写回内存的操作会使在其他CPU里缓存了改内存地址的数据无效。  
为了确保各个处理器的缓存是一致的，就会实现缓存一致性协议，每一个处理器都会去嗅探在总线上传播的数据来检查自己缓存的值是不是过期了。
当发现自己缓存行内对应的内存地址被修改，就会将当前缓存行设置成无效状态，当处理器对这个数据进行操作的时候，那就直接从系统内存中把这个数据读到处理器的缓存里面。

**Lock前缀的指令会引起处理器缓存回写到内存：**    
Lock这个指令不会锁总线，而是锁缓存，锁总线的开销比较大。 
   
**一个处理器的缓存回写到内存，会导致其他处理器上的缓存无效：**    
Intel的处理器会使用MESI控制协议去维护内部缓存和其他处理器缓存的一致性。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器缓存的书记在总线上保持一致。

### volatile的优化
Doug lea在JDK7的并发包里面新增了一个队列集合类 Linked-TransferQueue,在使用volatile变量的时候使用了一种追加字节的方式来优化性能。他把共享变量的长度追加多个4个字节的引用扩充到64个字节。    
因为intel的多款CPU的l1,l2,l3缓存的高速缓存行都是64个字节宽的，并且是不支持部分行填充的，采用这种追加字节填满到缓存行宽度的办法，处理器就会把这个数据都读到同一个高速缓存行里面。  


## synchronized的实现原理和应用
普通同步方法：锁是当先实例对象  
静态同步方法：锁是当前类的Class对象  
同步方法块：  锁是括号里面的对象  

JVM基于进入和退出Monitor对象实现同步，代码块是使用monitorenter和monitorexit来实现。对于方法，在编译之后会被标识为ACC_SYNCHRONIZED也是隐式的调用了这一组指令。   
在编译之后，同步代码开始的地方插入monitorenter指令，在异常和方法结束的时候插入monitorexit指令，JVM保证了相互匹配，并且在异常的时候也能正常释放monitor对象，避免死锁。    
### Java对象头
synchronized用的锁存在Java对象头里面，如果对象是数组，JVM用3个字宽存储对象头，非数组用2个字宽。
Java的对象头存储了对象的HashCode,分代年龄和锁标记位。

### 锁升级

JDK1.6引入了偏向锁和轻量级锁。 
- 1、偏向锁  
HotSpot虚拟机的作者研究发现，大多数情况下锁不仅不存在竞争，并且是由一个线程多次获得。所以当一个线程访问同步代码块的时候，就会在对象头和栈帧中的锁记录里面存放偏向线程的ID。
之后在进入和退出同步代码块的时候只需要简单的判断一下对象头里面的值是不是存储着当前线程，成功则就代表线程已经获得了锁，失败则使用CAS去竞争一下这个锁。
偏向锁的撤销采用了一种有竞争出现的时候才释放锁的机制。先暂停拥有偏向锁的线程，然后检测持有偏向锁的线程是不是出于活动状态，如果是，那就撤销偏向锁，把对象头里面的偏向线程删除，标记对象不适合作为偏向锁。
关闭偏向锁：-XX:-UseBasedLocking=false

- 2、轻量级锁
线程在执行同步代码块之前，JVM会首先在当前线程的栈帧中创建用于存储锁记录空间,然后将对象头中的Mark Work复制到自己的锁记录中，然后尝试用CAS将对象头的锁换成自己。
成功则代表当前线程获得了锁，失败则表示自己在同其他线程一起竞争这个锁，当前线程就会自旋一段时间来尝试获取锁。
当两个线程同时CAS竞争锁资源的时候，就会将轻量级锁膨胀为重量级的锁。

- 3、重量级锁就是避免无用的自旋去消耗过多CPU的资源，当处于重量级锁状态下，其他线程想要获得锁就都会被阻塞住，拥有者释放之后才会进行新的竞争。
  
|锁|优点|缺点|适用场景|
|---|---|---|---|
|偏向锁|加锁过程不需要额外的消耗，和执行普通的方法相比基本没有差距|如果线程之间存在锁竞争，会带来额哇哦的锁撤销的消耗|适用于只有一个线程访问同步代码块的情况|
|轻量级锁|竞争的线程不会阻塞，响应速度提升|如果始终得不到锁竞争的线程，自旋会消耗CPU|追求响应时间、同步代码块执行的时间周期不长|
|重量级锁|不会消耗CPU|线程阻塞，响应时间慢|追求吞吐量，同步代码块执行的时间周期比较长|

### 原子操作的实现原理
原子操作：不能被分割的一个或者一系列操作。

**CPU术语**
缓存行：缓存的最小操作单位。    
比较并交换：先比较旧值和期望值是否一致，不一致就重新读取旧值，一致就变化成新值。  
CPU流水线：在CPU中由5~6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5~6步后再由这些电路单元分别执行，
这样就能实现在一个CPU时钟周期完成一条指令，用这种方式来提高CPU的运算速度。  
内存顺序冲突：一般是由假共享问题引起的。假共享问题指的是，多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，
当出现这个内存顺序冲突的时候，CPU必须清空流水线。

#### 处理器是如何实现原子操作的？
使用基于缓存加锁或者总线加锁的方式。  
处理器首先保证基本对内存操作的原子性，当一个处理器访问内存中的一个字节的时候，其他的处理器不能访问这个地址。  
但是对复杂内存操作的时候，处理器是不能自动保证原子性的（跨总线调度，跨缓存行），处理器提供了总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 
 
##### 锁总线机制
多个CPU对同一个共享变量操作的时候，另外的CPU不能操作该共享变量内存地址的缓存。
总线锁就是使用处理器提供的LOCK#信号，当一个处理器在总线上输出此信号的时候，其他处理器的请求被阻塞，这个处理器可以独占共享内存。

##### 缓存锁定机制
总线锁把其他CPU和内存之间的通讯锁住了，这个期间其他处理器不能操作其他内存地址的数据，总线锁的开销比较大。目前一般都是使用缓存锁定代替总线锁定来进行优化。  
计算出来的数据会放在CPU的L1,L2,L3三级高速缓存里。
如果内存中的数据被缓存再了高速缓存里面，并且这些内存地址在LOCK期间被锁定了，那么当执行锁操作回写到内存的时候，处理器不在总线上发出LOCK#信号，而是修改内部的内存地址，
允许它的缓存一致性机制来保证操作的原子性。缓存一致性机制会阻止同时修改由两个以上的处理器缓存的内存区域数据，当其他处理器回写已经锁定的缓存行数据的时候，会使得缓存行无效。

##### 处理器不会使用缓存锁定的两种情况
1、数据不能被缓存在处理器里面，或者操作的数据跨多个缓存行，处理器会使用总线锁定。  
2、有些处理器不支持缓存锁定


#### Java如何实现原子操作？
通过CAS和锁的方式来实现。
**CAS**
JDK1.5之后提供了一些原子支持的包装类。AtomicInteger，AtomicBoolean......  
CAS的三大问题：  
1、ABA问题 （AtomicStampedReference类能解决）  
2、循环时间长会导致开销大。  
3、只能保证对一个共享变量的原子操作。  
**锁机制**
锁机制是保证只有获得锁的线程才能操作锁定的内存区域。JVM层面的锁在底层都使用了CAS

# 第三章 Java内存模型
## 3.1 Java内存模型
Java并发采用的是共享内存模型，线程之间的通信是隐式进行的办法。  
Java的所有实例域、静态域和数组元素等都是在堆内存中，所有线程共享局部变量。

### 指令排序
1、编译器优化排序
2、处理器排序
3、内存系统重排序

为了保证可见性，Java编译器在生成指令序列的适当位置插入内存屏障指令来禁止特定类型的处理器重排序。
as-if-serial原则：编译器和处理器不会对存在数据依赖关系的操作做重排序。但是如果数据不存在依赖关系，这些操作就可能被编译器和处理器重排序。
as-is-serial造成一个幻觉，单线程程序按照顺序执行，但是在多线程环境下就变得不一样。

### 3.3顺序一致性
顺序一致性内存模型：
1、一个线程中的所有操作必须按照程序的顺序来执行。
2、不管程序是否同步，所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行并且立刻对所有线程可见。


# 第四章 Java并发编程基础
## 4.1 线程简介
操作系统调度的最小单元是线程。线程拥有各自的计数器、堆栈和局部变量等属性。
更多的处理器核心、更快速的响应时间、更好的编程模型。
现在大多数计算机都比以往更加擅长并行计算，而处理器性能的提升方式，也从更高的主频向更多的核心发展。如何利用好处理器上的多个核心也成了现在的主要问题。

Java的线程，默认的优先级是5，可以通过一个priority的属性去调节优先级。但是，这个优先级一般是失效的。程序的正确性不能依赖线程的优先级高低。
## 4.3 线程之间的通信
### 等待/通知 机制
一个线程A调用了对象O的wait()方法进去等待状态，而另一个线程B调用O的notify()或者notifyAll()方法，
线程A收到通知之后从对象的wait()方法返回，执行后续的操作。

```

消费者(等待方)：
synchronized(对象){
    while(条件不满足){
        对象.wait();
    }
    满足时候的处理逻辑
}


生产者(通知方)
synchronized(对象){
    改变条件
    对象.notifyAll();
}

```

如果一个线程执行了thread.join()语句，其含义是：
当前线程A等待thread线程终止之后才从thread.join()返回。

## 4.4 线程应用实例
1、等待超时模式
调用一个方法等待一段时间，如果能在事件只能正常返回就返回计算结果。如果不能则返回默认结果。
数据库连接池，通过构造函数初始化连接的最大上限，一个双向链表来维护连接。


# 第五章 Java并发编程基础
## 5.1 Lock接口
锁是用来控制多个线程访问共享资源的方式，一个锁能够防止多个线程同时访问共享资源。  
JDK5之后，并发包中增加了Lock接口，提供了与Synchronized类似的功能，拥有了锁获取与释放的可操作性、可中断的获取、以及超时获取锁等多种synchronized不具备的同步特性。
  
对于一些锁释放的条件有约束的业务情景，Lock比synchronized就会方便很多。  
Lock接口的实现基本都是通过聚合了一个同步去的子类来完成线程访问控制的。  

Lock的API简介：  
|方法名称|描述|
|---|---|
|void lock()|获取锁，获取锁之后当前线程会获取锁，获得之后，从该方法返回|
|void lockInterruptibly()| 可中断的获取锁，会响应中断|
|boolean tryLock()|尝试非阻塞的获取锁|

## 5.2 队列同步器
AbstractQueuedSynchronizer，同步器，是用来构建锁或者其他同步组件的基础框架。  
使用一个int的成员变量标识同步状态，内助FIFO的队列来完成资源获取线程的排队工作。  
同步器仅仅是定义了若干同步状态获取和释放的方法来供给自定义的同步组件使用，可以是独占式的，也可以是共享式的。
这样就可以实现不同类型的同步组件（ReentrantLock、CountDownLatch等等）

同步器是实现锁的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。  
锁是面向使用者的，使用者和锁的交互。  
同步器是锁的实现，简化了锁的实现方式，屏蔽了同步状态管理，线程的排队、等待和唤醒等底层操作。  

### 队列同步器的接口与实例
重写同步器的指定方法的时候，需要使用同步器提供的以下三个方法来访问或者修改同步状态：
getState() 获取当前同步状态。  
setState(int newState) 设置当前同步状态。  
compareAndSetState(int expect,int updated) CAS设置当前状态，能保证原子性。

**可重写的方法：**  
boolean tryAcquire(int arg) 独占式获取同步状态，实现该方法需要查询当前状态并且判断同步状态是否符合预期，然后进行CAS设置同步状态。  
boolean tryRelease(int arg) 独占式释放同步状态没等待获取同步状态的线程将有机会获取同步状态。  
int tryAcquireShared(int arg) 共享式获取同步状态,返回值大于等于0 获取成功，小于0则失败
boolean tryReleaseShared(int arg) 共享式释放同步状态
boolean isHeldExclusively() 当前线程同步器是否在独占模式下被线程占用，一般该方法标识是否被当前线程所占用。

**同步器提供的模板方法:**
独占式获取与释放（acquire、release、tryAcquiredNanos）  
共享式获取与释放（acquireShared、releaseShared、tryAcquiredSharedNanos）  
查询同步队列中等待线程情况（getQueuedThreads） 

### 队列同步器的实现分析
#### 1、同步队列
同步器依赖内部的一个FIFO的双向队列来完成同步状态的管理。  
当前线程获取同步状态失败的时候，同步器会将当前线程以及等待状态等信息构造成一个节点并且加入到同步队列中，同时也会阻塞当前线程，当同步状态释放的时候，会把首节点中的线程唤醒，使其再次尝试获取同步状态。

**节点属性**  
```
int waitStatus     等待状态
    0  INITIAL     初始状态
    
    1  CANCELLED   由于在同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待，
       节点进入该状态将不会变化
       
   -1  SINGAL      后继节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，
       会通知后继节点，是后继节点的线程得以运行
       
   -2  CONDITION   节点在等待队列中，节点线程等待在Condition上，当其他线程对Condition调用了signal()方法之后，
       该节点将会从等待队列中转义到同步队列中，假如到对同步转改的获取中

   -3  PROPAGATE   表示下一次共享式同步状态将会无条件的被传播下去
   
Node pev  前驱节点 当节点加入同步队列时候被设置（尾部添加）

Node next 后继节点

Node nextWatier 等待队列中的后继节点，如果当前节点是共享的，那么这个字段将是一个shared常量，也就是说节点类型（独占或者共享）和等待队列中的后继节点共享同一个字段

Thread thread 获取同步庄涛的线程
```
**队尾线程安全**  
没有获取到同步状态的线程会成为节点加入到队列的尾部  
因为节点中存在前驱后继的引用关系，而新的线程是加入到队列的尾部，所以尾部元素的引用关系是要保证线程安全的，也就是会使用一个CAS的方法去设置队尾节点：
compareAndSetTail(Node expect,Node update)  
  
**首节点设置**  
首节点是获取同步状态成功的节点，首节点的线程在释放同步状态的时候，会唤醒后继节点，后继节点在获取同步状态成功的时候会将自己设置为首节点。
头结点的设置方法不需要使用CAS,只需要将首节点设置成为原来首节点的后继节点，并且断开引用关系即可。


#### 2、独占式同步状态获取与释放
调用同步器的acquire(int arg) 方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状态失败后会进入同步队列中，
后续对线程进行中断操作的时候，线程不会从同步队列中移除。
```

获取同步状态方法 acquire(int arg);

public final void acquire(int arg){
    if( ! tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE),arg))
        selfInterrupt();
}

Node.EXCLUSIVE 表示同一个时刻只能有一个线程成功获取同步状态

首先调用自定义同步器实现tryAcquire()方法，该方法保证线程安全的获取同步状态
如果失败则构造同步节点，并且通过addWaiter()方法将该节点加入到同步队列的队尾
最后调用acquireQueued()方法使得该节点以死循环的方式获取同步状态
如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现

-------------------------------------------------------------------------------------------

将节点加入到同步队列的尾部 addWaiter(Node node)

private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    //快速尝试在尾部添加
    Node pred = tail;
    if (pred != null) {
          node.prev = pred;
          if (compareAndSetTail(pred, node)) {
                pred.next = node;
                return node;
          }
    }
    enq(node);
    return node;
}

compareAndSetTail(Node expect, Nodeupdate) 方法来确保节点能够被线程安全添加

-------------------------------------------------------------------------------------------


"死循环"把Node添加到队列的尾部 enq(final Node node)

private Node enq(final Node node) {
    for (;;) {
          Node t = tail;
          if (t == null) {
          
                if (compareAndSetHead(new Node()))
                          tail = head;
                          
          } else {
          
                node.prev = t;
                if (compareAndSetTail(t, node)) {
                        t.next = node;
                        return t;
                }
                
            }
      }
}

节点进入到同步队列之后，就进入一个自旋的过程，每个节点都会自省的观察，
当条件满足的时候，获取到了同步状态，就可以从这个自旋的过程中退出。

-------------------------------------------------------------------------------------------


```






































